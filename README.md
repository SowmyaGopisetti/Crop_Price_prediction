# Crop_Price_prediction
The dataset is with the following features: State, Crop, CostCultivation, CostCultivation2, Production, Yield, Temperature, RainFallAnnual, and Price (target variable). Since the target is already present in the dataset, this is a supervised learning task, and because the target feature is continuous, the prediction is done using regression models.

In this project, I predicted the price using three models: Linear Regression, Support Vector Regression, and Decision Tree Regression. Their R2 scores and mean square errors were compared to evaluate performance.

ğğ«ğ¨ğ£ğğœğ­ ğ–ğ¨ğ«ğ¤ğŸğ¥ğ¨ğ°:

ğ„ğ±ğ©ğ¥ğ¨ğ«ğšğ­ğ¨ğ«ğ² ğƒğšğ­ğš ğ€ğ§ğšğ¥ğ²ğ¬ğ¢ğ¬ (ğ„ğƒğ€):

This is done to get a better understanding of the data which involved checking for null values, checking the shape of the data and checking for duplicates. I checked for the collinearity among the features by visualizing a scatter pair plot among the continuous features. My observation revealed that CostCultivation and CostCultivation2 were collinear as the scatter plot was linear between them. So, to handle that I used a feature engineering technique by making a new column CostCultivation_product which is the product of CostCultivation and CostCultivation2.

ğƒğšğ­ğš ğ“ğ«ğšğ§ğ¬ğŸğ¨ğ«ğ¦ğšğ­ğ¢ğ¨ğ§:

Plotted histograms for continuous features and applied log transformation to those not normally distributed.

Used boxplots to detect and handle outliers.

Data Preparation:

Split the dataset into X (features) and Y (target variable).

Further, split the data into training (80%) and testing (20%) sets, resulting in X_train, X_test, Y_train, and Y_test.


ğŒğ¨ğğğ¥ ğ“ğ«ğšğ¢ğ§ğ¢ğ§ğ  ğšğ§ğ ğ„ğ¯ğšğ¥ğ®ğšğ­ğ¢ğ¨ğ§:

Trained and evaluated Linear Regression, Support Vector Regression, and Decision Tree Regression models and Compared models using RÂ² scores and mean square errors.


ğ‘ğğ¬ğ®ğ¥ğ­ğ¬:

Linear Regression: RÂ² Score: 0.99

Support Vector Regression: RÂ² Score: 0.99

Decision Tree Regression: RÂ² Score: 0.98
